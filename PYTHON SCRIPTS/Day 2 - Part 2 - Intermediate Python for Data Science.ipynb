{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ae79e37-1f33-4956-8dd6-1fe86fbe9c64",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# APIs and web scraping in Python\n",
    "\n",
    "Connecting to a remote web API in Python is easy with the `requests` library (https://requests.readthedocs.io/en/latest/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2b1bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5e8a43",
   "metadata": {},
   "source": [
    "To *get* data from an API, we make an HTTP GET request.\n",
    "\n",
    "All we need is the url.\n",
    "\n",
    "We will use the Star Wars API at https://swapi.dev.\n",
    "    \n",
    "Their \"root\" API returns all the possible API endpoints and their urls, let's start there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612e49d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://swapi.dev/api\"\n",
    "\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328969c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0082dfe",
   "metadata": {},
   "source": [
    "Every HTTP response comes with a *status code* which tells us whether the request was successful.\n",
    "\n",
    "- 200 means everything was fine\n",
    "- values in the 300 range mean some sort of redirection happened\n",
    "- the 400 range means client error - the requester did something wrong like type an incorrect url (404 means \"not found\" for example)\n",
    "- the 500 range means server error - the request was fine but the web server encountered a problem in trying to respond\n",
    "\n",
    "If you ever want to know what a status code means, you can use the website http.cat, e.g. https://http.cat/404"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03451aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc1dd7e",
   "metadata": {},
   "source": [
    "There is also a convenience method to check if the response errored. This does nothing if the request was fine, otherwise it will raise an exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dab6104",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.raise_for_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a94270c",
   "metadata": {},
   "source": [
    "The response object contains the response as raw text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcadf867",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830e0c25",
   "metadata": {},
   "source": [
    "But if the data is sent back in JSON format we can convert the response to a Python object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689102bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_json = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e43d44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(response_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b12c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3774b316",
   "metadata": {},
   "source": [
    "And now we can access the data inside it like any other Python object!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b1069d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_json[\"people\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d55e4d-2ff0-4e2c-a113-269a8bcd7069",
   "metadata": {},
   "source": [
    "Let's actually call one of these APIs to gather some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db043cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_url = response_json[\"people\"]\n",
    "\n",
    "people = requests.get(people_url).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4b1bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f555f4-5513-405e-85e8-90541dcef206",
   "metadata": {},
   "outputs": [],
   "source": [
    "people[\"results\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc09683a-94b0-4fd8-8744-6dce01de6c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "people[\"results\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5165fb7",
   "metadata": {},
   "source": [
    "<h1 style=\"color: #fcd805\">Exercise: APIs</h1>\n",
    "\n",
    "1. Every endpoint in the Star Wars API supports searching. Read the documentation at https://swapi.dev/documentation#search and see if you can search the database to find **Darth Vader's height**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f17455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3f500fd",
   "metadata": {},
   "source": [
    "2. Find the **endpoint** (i.e. the specific url) responsible for returning data about starships.\n",
    "\n",
    "Use this endpoint to search the database and find the Millennium Falcon.\n",
    "\n",
    "What is its **cargo capacity**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7fd47e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d6b91ce",
   "metadata": {},
   "source": [
    "3. Every starship record contains links to its pilots. Find the characters who have piloted the Millennium Falcon and print their names.\n",
    "\n",
    "*Hint: you may need to make further API calls...!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32078cfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "808518cd",
   "metadata": {},
   "source": [
    "## Converting API data to `pandas`\n",
    "\n",
    "Not only can we convert an API response to a Python object, we can convert it to a `pandas` DataFrame (if we have a list of values).\n",
    "\n",
    "Let's use the endpoint to give us a collection of people:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c414208",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "people_response = requests.get(\"https://swapi.dev/api/people\")\n",
    "\n",
    "people_response.raise_for_status()\n",
    "\n",
    "people = people_response.json()\n",
    "\n",
    "people"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7add3626",
   "metadata": {},
   "source": [
    "`pandas` interprets a list of dictionaries as a collection of rows.\n",
    "\n",
    "Keys in the dictionaries become columns and the values become the row values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3e5244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "people_df = pd.DataFrame(people[\"results\"])\n",
    "\n",
    "people_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6aff490-4cf5-4e0e-8584-a042a84a106e",
   "metadata": {},
   "source": [
    "Let's now enhance the data by downloading details of each person's homeworld.\n",
    "\n",
    "We can do this by calling the url in the `homeworld` column and saving the returned values to another column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf737f3-8595-4485-914a-ea39db5db127",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_homeworld_data(url):\n",
    "    try:\n",
    "        return requests.get(url).json()\n",
    "    except Exception as e:\n",
    "        return None  # Return None in case of any errors\n",
    "\n",
    "# Apply the function to the 'homeworld' column and save the result in 'homeworld_data'\n",
    "people_df['homeworld_data'] = people_df['homeworld'].apply(fetch_homeworld_data)\n",
    "\n",
    "people_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cab3628",
   "metadata": {},
   "source": [
    "Pretty good! But we ran into a problem because the `homeworld_data` column is a dictionary.\n",
    "\n",
    "We can \"unpack\" this in `pandas` into separate columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bf268c-bcd0-47d1-ae9a-79db0a52aed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_homeworlds = pd.json_normalize(people_df[\"homeworld_data\"])\n",
    "people_homeworlds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f81ae0-90f2-4733-83ad-341cdacf5821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll rename columns to start with `homeworld_`\n",
    "people_homeworlds.columns = [\"homeworld_\" + c for c in people_homeworlds.columns]\n",
    "\n",
    "people_homeworlds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58b904b",
   "metadata": {},
   "source": [
    "Now all that remains is to put these two datasets together.\n",
    "\n",
    "This isn't a join, we actually just want to connect the two `DataFrame`s side by side without a join key.\n",
    "\n",
    "We can do this with `.concat()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de49e955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat takes a LIST of DataFrames\n",
    "# axis is either 0 (horizontal, two DataFrames on top of one another)\n",
    "# or 1 (vertical, two DataFrames side by side)\n",
    "people_df_final = pd.concat([people_df, people_homeworlds], axis=1)\n",
    "people_df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aff8a31",
   "metadata": {},
   "source": [
    "We can also drop the original `homeworld` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48d9d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_df_final = people_df_final.drop(columns=[\"homeworld\"])\n",
    "\n",
    "people_df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e30a32",
   "metadata": {},
   "source": [
    "We need to some data cleaning and type conversion, but otherwise we can analyse this data in `pandas`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40c9cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_df_final[\"homeworld_climate\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bcb4c8-d505-4161-b7ed-dd752c0b7cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "people_df_final[\"homeworld_orbital_period\"] = people_df_final[\"homeworld_orbital_period\"].replace(\"unknown\", np.nan)\n",
    "people_df_final[\"homeworld_orbital_period\"] = people_df_final[\"homeworld_orbital_period\"].astype(float)\n",
    "\n",
    "people_df_final[\"homeworld_orbital_period\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50c9c23",
   "metadata": {},
   "source": [
    "### API keys\n",
    "\n",
    "Most APIs require authentication of some sort.\n",
    "\n",
    "Often this just means signing up for an API key, which is a string that's unique to you. Keep it safe, like a password.\n",
    "\n",
    "Depending on the API, using a key can be as easy as adding it into the url as an extra parameter.\n",
    "\n",
    "For example, Alpha Vantage (a free API service for stock price data) requires an email signup to generate a key.\n",
    "\n",
    "The example urls all have the key of `\"demo\"` which you simply replace with your own key:\n",
    "\n",
    "https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY&symbol=IBM&interval=5min&apikey=demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c8522a",
   "metadata": {},
   "source": [
    "<h1 style=\"color: #fcd805\">Exercise: APIs and `pandas`</h1>\n",
    "\n",
    "We're going to explore a new API, the Gutendex (https://gutendex.com/).\n",
    "\n",
    "This is an API to access data about the Project Gutenberg catalogue. Project Gutenberg (https://www.gutenberg.org/) is an initiative to digitise works of literature.\n",
    "\n",
    "The url to retrieve all books is https://gutendex.com/books.\n",
    "\n",
    "1. Look at the documentation on the website to figure out how to modify the url to get only books on the topic of horror.\n",
    "\n",
    "Call this url using `requests` to get a response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7bd2a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11a86eb9",
   "metadata": {},
   "source": [
    "2. Convert the response to a Python object. How many books are there in total that are tagged \"horror\"?\n",
    "\n",
    "_Hint: look at the response and find the right dictionary key to answer the question._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5d9323",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6249425",
   "metadata": {},
   "source": [
    "3. Find the right dictionary key within the returned result to retrieve the books as a list. Convert these to a `pandas` DataFrame.\n",
    "\n",
    "How many books were returned?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd13524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76e20520",
   "metadata": {},
   "source": [
    "4. Each request only retrieves 32 books, but we want all of them. Write a loop to go through all pages of the horror catalogue. In your loop you should:\n",
    "\n",
    "- request a new page of books by altering the url each time\n",
    "- take the results, save them into a Python object, then convert it to a `pandas` DataFrame\n",
    "- collect all these `pandas` DataFrames into a list\n",
    "\n",
    "At the end of your loop you should have a list of `pandas` DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7d28a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55648ec3",
   "metadata": {},
   "source": [
    "5. Use the `.concat()` method to combine your DataFrames into a single DataFrame.\n",
    "\n",
    "How many horror books do you have in your data? Does the number match the count from question 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32267dc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aadca9ac",
   "metadata": {},
   "source": [
    "6. How many downloads of horror books were there in total?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63d409d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18bd545b",
   "metadata": {},
   "source": [
    "7. BONUS: Which author has the most books in the horror section?\n",
    "\n",
    "To answer this:\n",
    "\n",
    "- the `authors` column is a list of dictionaries. Figure out how to extract the *first* dictionary from each list and save these into a new column\n",
    "- use this new column to \"unpack\" the dictionary using `json_normalize`\n",
    "- use this \"JSON normalised\" data to calculate the most frequent author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a40f24d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "975d6265",
   "metadata": {},
   "source": [
    "# Web scraping\n",
    "\n",
    "Web scraping is needed when data is on the web but not accessible with a clean API.\n",
    "\n",
    "In these instances, we can extract the data from the web page directly.\n",
    "\n",
    "We can use `requests` to get the raw HTML of a web page, which we can then explore.\n",
    "\n",
    "We're going to scrape data from a fictional bookstore: http://books.toscrape.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4961b4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bookstore_response = requests.get(\"http://books.toscrape.com/\")\n",
    "\n",
    "bookstore_response.raise_for_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52da5f9",
   "metadata": {},
   "source": [
    "The returned content is now not JSON, but raw HTML in a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b875000",
   "metadata": {},
   "outputs": [],
   "source": [
    "bookstore_response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab101724",
   "metadata": {},
   "source": [
    "To be able to extract components from this, we will use the `BeautifulSoup` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8f7d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8625ef1",
   "metadata": {},
   "source": [
    "We create a \"beautiful soup\" object from the raw HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a76b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(bookstore_response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c359ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a62ca1",
   "metadata": {},
   "source": [
    "Looking at the object, it still looks like the HTML but we have additional methods available to us to explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa95447",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ce1b16",
   "metadata": {},
   "source": [
    "What we're interested in is extracting specific HTML **elements**.\n",
    "\n",
    "For this, we need to learn a bit of syntax, which are technically CSS selectors. CSS is a way to style a web page (more info and tutorials here: https://www.w3schools.com/css/).\n",
    "\n",
    "The simplest form of a selector is using a tag type. That is, finding elements on a page that are all the same type, such as links.\n",
    "\n",
    "In HTML, a link is an `<a>` tag, so we can find all links like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152be5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = soup.select(\"a\")\n",
    "\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bb09a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9653ade9",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(links[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffb976f",
   "metadata": {},
   "source": [
    "These are all `Tag` objects which represent an HTML element.\n",
    "\n",
    "These link tags all contain:\n",
    "\n",
    "- text, which is what we see displayed on the page\n",
    "- an \"href\" which is the url to visit when you click the link\n",
    "\n",
    "We can extract both using `BeautifulSoup`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22cc369",
   "metadata": {},
   "outputs": [],
   "source": [
    "[link.text for link in links]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86eac843",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[link[\"href\"] for link in links]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4390ed0f",
   "metadata": {},
   "source": [
    "You might find many elements of the same type, but with a different `class`.\n",
    "\n",
    "A class is a way to tell CSS which elements should look the same.\n",
    "\n",
    "For example, all buttons on the webpage have the same classes, including one called `\"btn\"`.\n",
    "\n",
    "In CSS, to select all items of the same class, we can use `.` like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38001c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "buttons = soup.select(\".btn\")\n",
    "buttons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b05b0e",
   "metadata": {},
   "source": [
    "<h1 style=\"color: #fcd805\">Exercise: web scraping</h1>\n",
    "\n",
    "Your turn to scrape some data from the bookshop!\n",
    "\n",
    "We're going to extract all the prices from the page and calculate the average book price.\n",
    "\n",
    "1. Inspect the web page. What makes each book price element unique?\n",
    "\n",
    "_Hint: right-click and click Inspect to view the HTML behind an element on the page._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea50b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0288aee2",
   "metadata": {},
   "source": [
    "2. Use `BeautifulSoup` to select all the elements that show a book's price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1478a37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cac5a0ce",
   "metadata": {},
   "source": [
    "3. Extract only the displayed text from these elements into a list.\n",
    "\n",
    "You should end up with a list of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485884d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ddc1ee1",
   "metadata": {},
   "source": [
    "4. Create a `pandas` `Series` from this list of strings by using `pd.Series`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771cf613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ca67c3a",
   "metadata": {},
   "source": [
    "5. Using your `pandas` knowledge, clean up these strings so they are just numeric prices, and convert the `Series` to be a numeric type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9600b1d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d675d12",
   "metadata": {},
   "source": [
    "6. Now calculate the average price of books on the web page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d9c2d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
