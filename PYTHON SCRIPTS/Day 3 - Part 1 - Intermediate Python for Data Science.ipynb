{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ae79e37-1f33-4956-8dd6-1fe86fbe9c64",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Advanced `pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2b1bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fedd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "loans = pd.read_csv(\"./data/loans.csv\")\n",
    "\n",
    "loans.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce091f90",
   "metadata": {},
   "source": [
    "## Categorical data\n",
    "\n",
    "Generally, text columns should be converted to `string` types.\n",
    "\n",
    "However, if a column is categorical, we have a special data type we can use.\n",
    "\n",
    "Why would we want to do that?\n",
    "\n",
    "- the special `category` data type uses less memory\n",
    "- we can also specify the order of the categories\n",
    "\n",
    "Let's look at the first reason:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1933f9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loans[\"term\"].memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58484906",
   "metadata": {},
   "source": [
    "Converting to `string` doesn't save any memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894af3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loans[\"term\"].astype(\"string\").memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de59307",
   "metadata": {},
   "source": [
    "But converting it to a `category`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b399e2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loans[\"term\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39196e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loans[\"term\"].astype(\"category\").memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23f8d1e",
   "metadata": {},
   "source": [
    "Let's take employment length as an example of an *ordered* categorical column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6959675a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loans[\"emp_length\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d689ec2d",
   "metadata": {},
   "source": [
    "These aren't in the right order and sorting in ascending or descending order doesn't fix it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4600bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(loans[\"emp_length\"].dropna().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d60cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_dtype = pd.CategoricalDtype(['< 1 year', '1 year', '2 years',\n",
    "                                 '3 years', '4 years', '5 years',\n",
    "                                 '6 years', '7 years', '8 years',\n",
    "                                 '9 years', '10+ years'], ordered=True)\n",
    "loans[\"emp_length\"].astype(emp_dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad07782f",
   "metadata": {},
   "source": [
    "What if we look at the `.value_counts()` now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b30619",
   "metadata": {},
   "outputs": [],
   "source": [
    "loans[\"emp_length\"].astype(emp_dtype).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212e9221",
   "metadata": {},
   "source": [
    "## Reshaping\n",
    "\n",
    "There are a few methods built in to `pandas` to help reshape your data.\n",
    "\n",
    "Read all about them here: https://pandas.pydata.org/docs/user_guide/reshaping.html\n",
    "\n",
    "One important one is to cross-reference categorical columns.\n",
    "\n",
    "For example, what is the distribution of loan grades across different types of home owners?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0173dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "loans.pivot_table(index=\"home_ownership\",\n",
    "                  columns=\"grade\",\n",
    "                  values=\"id\",\n",
    "                  aggfunc=\"count\"\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b60289",
   "metadata": {},
   "source": [
    "`.crosstab()` does the same thing but has more limited options (but you could specify data from different sources since it's not tied to a single `DataFrame`). Different methods have different pros and cons!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c0e2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index=loans[\"home_ownership\"],\n",
    "            columns=loans[\"grade\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4a7cb1",
   "metadata": {},
   "source": [
    "Both methods allow you to specify what aggregation goes into the cells.\n",
    "\n",
    "We could look at the average loan amount for different combinations of home ownership and grade:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74390986",
   "metadata": {},
   "outputs": [],
   "source": [
    "loans.pivot_table(index=\"home_ownership\",\n",
    "                  columns=\"grade\",\n",
    "                  values=\"loan_amnt\",\n",
    "                  aggfunc=\"mean\"\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226a6246",
   "metadata": {},
   "source": [
    "Incidentally, this is where heatmaps come in handy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3476ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "avg_by_home_and_grade = loans.pivot_table(index=\"home_ownership\",\n",
    "                                          columns=\"grade\",\n",
    "                                          values=\"loan_amnt\",\n",
    "                                          aggfunc=\"mean\"\n",
    "                                         )\n",
    "\n",
    "_ = sns.heatmap(\n",
    "    data=avg_by_home_and_grade,\n",
    "    vmin=0,\n",
    "    cmap=\"Greens\",\n",
    "    square=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b59394",
   "metadata": {},
   "source": [
    "## Custom methods\n",
    "\n",
    "Sometimes you want to perform a calculation on a column that's more advanced than what's already built in.\n",
    "\n",
    "In these cases you can use the general `.apply` method, which applies a custom function to all rows.\n",
    "\n",
    "Compared to other `pandas` operations, this is *slow*, but it's still quicker than using a loop.\n",
    "\n",
    "Suppose we have rules for what makes a loan a \"special\" case:\n",
    "\n",
    "- grade has to be B\n",
    "- interest rate over 10%\n",
    "- job title is \"Accountant\"\n",
    "\n",
    "and we want to label our data with these rules.\n",
    "\n",
    "Let's see the custom function approach.\n",
    "\n",
    "When we write a custom function, the argument is either:\n",
    "\n",
    "- a single value (if we want to apply the function to a single row or column)\n",
    "- an entire row (or column) of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b84230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_special_loan(row):\n",
    "    # only returns True if all conditions are met\n",
    "    return row[\"grade\"] == \"B\" and row[\"int_rate\"] > 10 and row[\"emp_title\"] == \"Accountant\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c47ca4",
   "metadata": {},
   "source": [
    "We can then pass the function to `.apply` making sure `axis` is set to 1 (apply the function to each row), not 1 (which applies the function to each column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27163fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "loans.apply(is_special_loan, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8bcbc6",
   "metadata": {},
   "source": [
    "Of course, we could have done this with \"raw\" `pandas` in a vectorised way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af97cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "loans[(loans[\"grade\"] == \"B\") & (loans[\"int_rate\"] > 10) & (loans[\"emp_title\"] == \"Accountant\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1821f5de",
   "metadata": {},
   "source": [
    "***Takeaway: only use `.apply` if there is no built-in `pandas` equivalent to what you want to do!***\n",
    "\n",
    "## Method chaining\n",
    "\n",
    "To really improve your `pandas` code, you can make use of **method chaining**.\n",
    "\n",
    "This is when you add methods one after another, which you can do because `pandas` returns a copy of the `DataFrame` each time.\n",
    "\n",
    "A classic read on the subject is here (a bit dated since `pandas` has much newer versions, but the ideas stand): https://tomaugspurger.net/posts/method-chaining/.\n",
    "\n",
    "Consider this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae27adf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_1 = pd.read_csv(\"./data/loans.csv\")\n",
    "\n",
    "loans_1[\"installment_pct\"] = loans_1[\"installment\"] / loans_1[\"loan_amnt\"]\n",
    "\n",
    "# do we want to overwrite the raw loans data?\n",
    "# or create loans_2?\n",
    "loans_1 = loans_1.dropna(subset=[\"emp_length\"])\n",
    "\n",
    "loans_1[\"emp_length\"] = loans_1[\"emp_length\"].astype(emp_dtype)\n",
    "\n",
    "income_by_emp = loans_1.groupby(\"emp_length\")[\"annual_inc\"].mean().sort_index(ascending=False)\n",
    "\n",
    "_ = income_by_emp.plot(kind=\"barh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7575635",
   "metadata": {},
   "source": [
    "You could also do all those operations in a single block:\n",
    "\n",
    "- more readable\n",
    "- steps are logically listed in the same place\n",
    "- you don't overwrite the source data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ca36d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_1 = pd.read_csv(\"./data/loans.csv\")\n",
    "\n",
    "_ = (\n",
    "    loans_1\n",
    "    .assign(\n",
    "        installment_pct=lambda df_: df_[\"installment\"] / df_[\"loan_amnt\"],\n",
    "        emp_length=lambda df_: df_[\"emp_length\"].astype(emp_dtype)\n",
    "    )\n",
    "    .dropna(subset=[\"emp_length\"])\n",
    "    .groupby(\"emp_length\")\n",
    "    [\"annual_inc\"]\n",
    "    .mean()\n",
    "    .sort_index(ascending=False)\n",
    "    .plot(kind=\"barh\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f46c728",
   "metadata": {},
   "source": [
    "This style of coding is entirely optional, but has a lot of benefits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19b4d9e-8942-4214-bf7f-abef75c53331",
   "metadata": {},
   "source": [
    "<h1 style=\"color: #fcd805\">Exercise: Advanced pandas</h1>\n",
    "\n",
    "Load in the Kickstarter data again.\n",
    "\n",
    "For these questions, see if you can use the method chaining style of coding to solve the problems.\n",
    "\n",
    "1. Convert the `state` column to be categorical. Choose a specific ordering for the states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f4da16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68af33d5",
   "metadata": {},
   "source": [
    "2. Calculate the average goal amount per state and display the results as a bar chart. Verify that the ordering you specified in your previous step has been taken into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eb5647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5fbfa052",
   "metadata": {},
   "source": [
    "3. What is the distribution of the `state` variable across different categories?\n",
    "\n",
    "You should create a table with one row per category and one column per state. The cell values should be the number of projects for each category-state pair, e.g.\n",
    "\n",
    "| |Failed|Succeed|\n",
    "|---|---|---|\n",
    "|**Art**|100|60|\n",
    "|**Food**|72|103|\n",
    "|**Music**|1412|835|\n",
    "\n",
    "(Note, this isn't real data, just an illustration of the structure you're aiming for!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd55289",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1a99109",
   "metadata": {},
   "source": [
    "4. Create a heatmap to visualise the table you created in step 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c070ea88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f56f068",
   "metadata": {},
   "source": [
    "5. We're going to find the projects that *nearly* made it.\n",
    "\n",
    "5.a. First, create a column to calculate the pledged amount as a percentage of the project goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932949c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb3f50d8",
   "metadata": {},
   "source": [
    "5.b. Now, write a Python function that determines is a project nearly made it.\n",
    "\n",
    "The function should return True *only* if the following conditions are met for a single row:\n",
    "\n",
    "- the goal was less than $100,000\n",
    "- the state was `\"failed\"`\n",
    "- the pledge as a percentage of the goal was over 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ecb906",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51da97dd",
   "metadata": {},
   "source": [
    "5.c. Use `.apply` on your `DataFrame` to call your function on all rows. Save the result in a column which indicates whether a project nearly made it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342b9a3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9e2e2d4",
   "metadata": {},
   "source": [
    "5.d. Using your new column, how many projects nearly made it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da873fca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4822f907",
   "metadata": {},
   "source": [
    "<h1 style=\"color: #fcd805\">Exercise: Changing names</h1>\n",
    "\n",
    "We're going to investigate how the popularity of names has changed over time.\n",
    "\n",
    "What names are popular changes over time. To illustrate this, several articles pointed out that in 2013 only 28 babies were named Gary in the UK, whereas it was once a much more popular choice.\n",
    "\n",
    "Let's see how the popularity of names has changed in recent years.\n",
    "\n",
    "Our data comes from the Office of National Statistics: [baby names](https://www.ons.gov.uk/peoplepopulationandcommunity/birthsdeathsandmarriages/livebirths/datasets/babynamesenglandandwalesbabynamesstatisticsboys).\n",
    "\n",
    "## Part 1 - reading and cleaning the data\n",
    "\n",
    "There are 3 Excel files for 2019, 2020, and 2021.\n",
    "\n",
    "1. Start by opening the 2019 file in Excel. Find where the raw count data is located for England and Wales (we want a list of boys names and their counts in a single, long table).\n",
    "\n",
    "Now, use the `read_excel` method in `pandas` to read the data into a `pandas` DataFrame.\n",
    "\n",
    "_Note: You will need to investigate and change some of the options!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9c08fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e920e7ad",
   "metadata": {},
   "source": [
    "2. Drop any columns you don't need (`pandas` might have read in some empty data!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d451888e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c88caf90",
   "metadata": {},
   "source": [
    "3. Use the `rename` function to rename any columns that need better names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41a768a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6603f6e0",
   "metadata": {},
   "source": [
    "4. Drop any rows you don't need. How can you identify rows that aren't actually part of your data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fc6164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e1d8497",
   "metadata": {},
   "source": [
    "5. Check the data types and convert any columns that need it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa1100e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a45f2bfc",
   "metadata": {},
   "source": [
    "6. Add a column to this DataFrame called `Year` which has the value 2019 for all rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba484f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27ea5b94",
   "metadata": {},
   "source": [
    "7. Repeat the process for the 2020 and 2021 files.\n",
    "\n",
    "You should end up with 3 DataFrames, one for each year.\n",
    "\n",
    "Things to ensure:\n",
    "\n",
    "- add the `Year` column with the correct year to each `DataFrame`\n",
    "- column names and data types should be identical in all `DataFrames`\n",
    "\n",
    "_Note: don't just run the same code with a different filename! Open each file and check that the data is stored in the same way, and amend your code if it isn't._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd597571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "172ea7e5",
   "metadata": {},
   "source": [
    "8. Use `pd.concat` to combine the 3 datasets into 1.\n",
    "\n",
    "Call your combined DataFrame `names`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a662da12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a637a68",
   "metadata": {},
   "source": [
    "9. Convert the name column to uppercase to ensure all names are uppercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21315f1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21af0ae9",
   "metadata": {},
   "source": [
    "10. Drop any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2beece7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4da01206",
   "metadata": {},
   "source": [
    "11. Use your `names` `DataFrame` to see how many Garys were born in each year from 2019 to 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449b9271",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33bb6201",
   "metadata": {},
   "source": [
    "## Part 2 - analysis\n",
    "\n",
    "Now that we have our raw data, let's investigate it.\n",
    "\n",
    "1. How many names are there in each year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34109d75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72b41fbb",
   "metadata": {},
   "source": [
    "2. Which name had the most occurrences in a given year across the entire data? That is, what is the highest number of occurrences of a name in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdeb2a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b2fbf0e",
   "metadata": {},
   "source": [
    "3. What is the most common first *letter* for boys' names?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bd6fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "599c863a",
   "metadata": {},
   "source": [
    "4. What are the 5 most common names overall? Save these names into a separate variable (e.g. a list or a `Series`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d2fb5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9da5f3c7",
   "metadata": {},
   "source": [
    "5. Now filter the `names` `DataFrame` so that only the top 5 names are kept (one row per name per year, so 15 rows in total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd0d36a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb359889",
   "metadata": {},
   "source": [
    "6. We are going to reshape this `DataFrame` to plot the frequency of each of the 5 names over time.\n",
    "\n",
    "To do this, our data needs to be **one column per line** on our line plot.\n",
    "\n",
    "In this case, that means:\n",
    "\n",
    "- one column per name\n",
    "- one row per year\n",
    "- values in the cells are the count of a particular name in a particular year\n",
    "\n",
    "Something like this (with dummy data):\n",
    "\n",
    "| |John|Joseph|David|\n",
    "|---|---|---|---|\n",
    "|**2019**|100|60|44|\n",
    "|**2020**|72|103|230|\n",
    "|**2021**|142|435|374|\n",
    "\n",
    "Reshape the `DataFrame` to achieve this format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d0785f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13553cbe",
   "metadata": {},
   "source": [
    "7. Call the `.plot` function on this data. You should see years on the x-axis, count on the y-axis and one line per name.\n",
    "\n",
    "Use your knowledge of `matplotlib` to clean up the visualisation and make it more presentation-ready, such as:\n",
    "\n",
    "- adding a title and axis labels\n",
    "- changing the \"tick labels\" (the values along the axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b55557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b2a3795",
   "metadata": {},
   "source": [
    "8. Now create a similar table, this time to track each name's rank over time.\n",
    "\n",
    "The table should have:\n",
    "\n",
    "- one row per name\n",
    "- one column per year\n",
    "- the values should be the **rank** of a name in a particular year (NaNs may be present for names that didn't appear in all years)\n",
    "\n",
    "Something like this:\n",
    "\n",
    "| |2019|2020|2021|\n",
    "|---|---|---|---|\n",
    "|**Robert**|407|392|232|\n",
    "|**Stephen**|101|75|44|\n",
    "|**Graham**|502|507|509|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2683cc07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a496fd8",
   "metadata": {},
   "source": [
    "9. Create a column in this table called `diff` which is the difference of a name's rank between 2021 and 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518e903f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3d6dfa0",
   "metadata": {},
   "source": [
    "10. Which names have moved up the most in the rankings and which ones have fallen the most?\n",
    "\n",
    "_Note: remember, in rankings, the lower the better!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c735c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
